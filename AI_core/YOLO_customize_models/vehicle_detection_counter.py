#!/usr/bin/env python3
"""
Script ph√°t hi·ªán v√† ƒë·∫øm ph∆∞∆°ng ti·ªán s·ª≠ d·ª•ng YOLOv8n
H·ªó tr·ª£ ƒë·∫øm theo v√πng (region) v√† theo ƒë∆∞·ªùng (line)
"""

import cv2
import argparse
from pathlib import Path
from ultralytics import YOLO
from ultralytics.solutions import ObjectCounter, RegionCounter
from ultralytics.utils import ASSETS

def vehicle_detection_simple(source, model_path="yolov8n.pt", device="cpu", show=True, save=False):
    """
    Ph√°t hi·ªán ph∆∞∆°ng ti·ªán ƒë∆°n gi·∫£n v·ªõi YOLOv8n
    
    Args:
        source: ƒê∆∞·ªùng d·∫´n video ho·∫∑c 0 cho webcam
        model_path: ƒê∆∞·ªùng d·∫´n model YOLOv8n
        device: Thi·∫øt b·ªã x·ª≠ l√Ω (cpu, 0, 1, ...)
        show: Hi·ªÉn th·ªã k·∫øt qu·∫£
        save: L∆∞u k·∫øt qu·∫£
    """
    
    # Load model
    model = YOLO(model_path)
    
    # Vehicle classes trong COCO dataset
    vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck
    
    # Ch·∫°y detection
    results = model.predict(
        source=source,
        device=device,
        classes=vehicle_classes,
        conf=0.5,
        show=show,
        save=save,
        verbose=True
    )
    
    return results

def vehicle_counting_line(source, model_path="yolov8n.pt", device="cpu", show=True, save=False):
    """
    ƒê·∫øm ph∆∞∆°ng ti·ªán qua m·ªôt ƒë∆∞·ªùng th·∫≥ng
    
    Args:
        source: ƒê∆∞·ªùng d·∫´n video ho·∫∑c 0 cho webcam
        model_path: ƒê∆∞·ªùng d·∫´n model YOLOv8n
        device: Thi·∫øt b·ªã x·ª≠ l√Ω
        show: Hi·ªÉn th·ªã k·∫øt qu·∫£
        save: L∆∞u k·∫øt qu·∫£
    """
    
    # Load model
    model = YOLO(model_path)
    
    # Vehicle classes
    vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck
    
    # ƒêi·ªÉm ƒë∆∞·ªùng ƒë·∫øm (c√≥ th·ªÉ thay ƒë·ªïi theo video)
    line_points = [(100, 400), (800, 400)]  # ƒê∆∞·ªùng ngang gi·ªØa m√†n h√¨nh
    
    # Kh·ªüi t·∫°o ObjectCounter
    counter = ObjectCounter(
        show=show,
        region=line_points,
        model=model_path,
        line_width=2,
        classes=vehicle_classes
    )
    
    # X·ª≠ l√Ω video
    cap = cv2.VideoCapture(source)
    assert cap.isOpened(), f"Kh√¥ng th·ªÉ m·ªü video: {source}"
    
    # L·∫•y th√¥ng tin video
    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
    
    # Video writer n·∫øu c·∫ßn l∆∞u
    if save:
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        video_writer = cv2.VideoWriter("vehicle_counting_output.avi", fourcc, fps, (w, h))
    
    print("üöó B·∫Øt ƒë·∫ßu ƒë·∫øm ph∆∞∆°ng ti·ªán...")
    print("üìä Nh·∫•n 'q' ƒë·ªÉ tho√°t")
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break
        
        # ƒê·∫øm ph∆∞∆°ng ti·ªán
        results = counter(frame)
        
        # Hi·ªÉn th·ªã th√¥ng tin
        print(f"V√†o: {counter.in_count}, Ra: {counter.out_count}, T·ªïng: {counter.in_count + counter.out_count}")
        
        # L∆∞u frame n·∫øu c·∫ßn
        if save:
            video_writer.write(results.plot_im)
        
        # Tho√°t n·∫øu nh·∫•n 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    if save:
        video_writer.release()
    
    print(f"\nüìä K·∫øt qu·∫£ cu·ªëi c√πng:")
    print(f"   Ph∆∞∆°ng ti·ªán v√†o: {counter.in_count}")
    print(f"   Ph∆∞∆°ng ti·ªán ra: {counter.out_count}")
    print(f"   T·ªïng: {counter.in_count + counter.out_count}")

def vehicle_counting_region(source, model_path="yolov8n.pt", device="cpu", show=True, save=False):
    """
    ƒê·∫øm ph∆∞∆°ng ti·ªán trong v√πng x√°c ƒë·ªãnh
    
    Args:
        source: ƒê∆∞·ªùng d·∫´n video ho·∫∑c 0 cho webcam
        model_path: ƒê∆∞·ªùng d·∫´n model YOLOv8n
        device: Thi·∫øt b·ªã x·ª≠ l√Ω
        show: Hi·ªÉn th·ªã k·∫øt qu·∫£
        save: L∆∞u k·∫øt qu·∫£
    """
    
    # Load model
    model = YOLO(model_path)
    
    # Vehicle classes
    vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck
    
    # Kh·ªüi t·∫°o RegionCounter
    counter = RegionCounter(
        show=show,
        model=model_path,
        line_width=2,
        classes=vehicle_classes
    )
    
    # Th√™m v√πng ƒë·∫øm (c√≥ th·ªÉ thay ƒë·ªïi theo video)
    # V√πng 1: G√≥c tr√°i tr√™n
    counter.add_region(
        name="Zone1",
        polygon=[(100, 100), (400, 100), (400, 300), (100, 300)],
        color=(255, 0, 0),  # M√†u ƒë·ªè
        text_color=(255, 255, 255)  # M√†u tr·∫Øng
    )
    
    # V√πng 2: G√≥c ph·∫£i d∆∞·ªõi
    counter.add_region(
        name="Zone2", 
        polygon=[(500, 300), (800, 300), (800, 500), (500, 500)],
        color=(0, 255, 0),  # M√†u xanh l√°
        text_color=(255, 255, 255)  # M√†u tr·∫Øng
    )
    
    # X·ª≠ l√Ω video
    cap = cv2.VideoCapture(source)
    assert cap.isOpened(), f"Kh√¥ng th·ªÉ m·ªü video: {source}"
    
    # L·∫•y th√¥ng tin video
    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
    
    # Video writer n·∫øu c·∫ßn l∆∞u
    if save:
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        video_writer = cv2.VideoWriter("vehicle_region_counting_output.avi", fourcc, fps, (w, h))
    
    print("üöó B·∫Øt ƒë·∫ßu ƒë·∫øm ph∆∞∆°ng ti·ªán theo v√πng...")
    print("üìä Nh·∫•n 'q' ƒë·ªÉ tho√°t")
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break
        
        # ƒê·∫øm ph∆∞∆°ng ti·ªán trong c√°c v√πng
        results = counter(frame)
        
        # Hi·ªÉn th·ªã th√¥ng tin
        print(f"Zone1: {counter.region_counts.get('Zone1', 0)}, Zone2: {counter.region_counts.get('Zone2', 0)}")
        
        # L∆∞u frame n·∫øu c·∫ßn
        if save:
            video_writer.write(results.plot_im)
        
        # Tho√°t n·∫øu nh·∫•n 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    if save:
        video_writer.release()
    
    print(f"\nüìä K·∫øt qu·∫£ cu·ªëi c√πng:")
    for zone_name, count in counter.region_counts.items():
        print(f"   {zone_name}: {count} ph∆∞∆°ng ti·ªán")

def main():
    parser = argparse.ArgumentParser(description="Ph√°t hi·ªán v√† ƒë·∫øm ph∆∞∆°ng ti·ªán v·ªõi YOLOv8n")
    parser.add_argument("--source", type=str, default="0", help="ƒê∆∞·ªùng d·∫´n video ho·∫∑c 0 cho webcam")
    parser.add_argument("--model", type=str, default="yolov8n.pt", help="ƒê∆∞·ªùng d·∫´n model YOLOv8n")
    parser.add_argument("--device", type=str, default="cpu", help="Thi·∫øt b·ªã x·ª≠ l√Ω (cpu, 0, 1, ...)")
    parser.add_argument("--mode", type=str, choices=["detect", "line", "region"], default="detect", 
                       help="Ch·∫ø ƒë·ªô: detect (ph√°t hi·ªán), line (ƒë·∫øm theo ƒë∆∞·ªùng), region (ƒë·∫øm theo v√πng)")
    parser.add_argument("--show", action="store_true", help="Hi·ªÉn th·ªã k·∫øt qu·∫£")
    parser.add_argument("--save", action="store_true", help="L∆∞u k·∫øt qu·∫£")
    
    args = parser.parse_args()
    
    print("üöó YOLOv8n Vehicle Detection & Counting")
    print("=" * 50)
    print(f"üìπ Ngu·ªìn: {args.source}")
    print(f"ü§ñ Model: {args.model}")
    print(f"üíª Thi·∫øt b·ªã: {args.device}")
    print(f"üéØ Ch·∫ø ƒë·ªô: {args.mode}")
    print("=" * 50)
    
    if args.mode == "detect":
        vehicle_detection_simple(args.source, args.model, args.device, args.show, args.save)
    elif args.mode == "line":
        vehicle_counting_line(args.source, args.model, args.device, args.show, args.save)
    elif args.mode == "region":
        vehicle_counting_region(args.source, args.model, args.device, args.show, args.save)

if __name__ == "__main__":
    main()
